# 是否爬取https的网页
crawler.worker.include.https=true
# 是否爬取二进制内容
crawler.worker.include.binary=false
# 每个页面抽取的最大数量的出链
crawler.worker.page.links.outgoing.max=5000
# 爬虫使用的user agent，默认设置为crawler4j的形式
crawler.worker.fetcher.userAgent="crawler4j (http://code.google.com/p/crawler4j/)"
# 套接字的超时时长
crawler.worker.fetcher.socket.timeout=2000
# 连接的超时时长
crawler.worker.fetcher.connection.timeout=3000
# 最大的连接数量
crawler.worker.fetcher.totalConnections.max=100
# 每台主机的最大连接数量
crawler.worker.fetcher.connectionsPerHost.max=100
# 下载页面的最大大小
crawler.worker.fetcher.downloadSizePerPage.max=1048576
# 是否follow重定向
crawler.worker.follow.redirects=false

crawler.worker.fetcher.proxy.host=
crawler.worker.fetcher.proxy.port=
crawler.worker.fetcher.proxy.user=
crawler.worker.fetcher.proxy.password=



